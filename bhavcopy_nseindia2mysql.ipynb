{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bhavcopy_nseindia2mysql.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1wpeVd-eds_hCQW83PZg9epPy9KzIGStl",
      "authorship_tag": "ABX9TyPb99wGHbt4nfAQ/n3b9QDB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyakini/algo_intraday/blob/master/bhavcopy_nseindia2mysql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCQ7pBunZZyl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "ce5585ae-b3b4-4ab4-b9db-2f69427a08dd"
      },
      "source": [
        "import requests, zipfile, os, io, pandas as pd\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "import csv\n",
        "from progressbar import ProgressBar\n",
        "#set the path to where the bhavcopies will be downloaded\n",
        "base = '/content/drive/My Drive/algotrade/'\n",
        "today = datetime.today().date()\n",
        "dmonth={'01':'JAN','02':'FEB','03':'MAR','04':'APR','05':'MAY','06':'JUN','07':'JUL','08':'AUG','09':'SEP','10':'OCT','11':'NOV','12':'DEC'}\n",
        "\n",
        "# Before running this script , file called bhavcopy_date.txt need to be present in the \"base\" path.\n",
        "# Opening file named bhavcopy_date.txt , it keeps track of the last downloaded date.\n",
        "ltdl = open(base+'bhavcopy_date.txt','r')\n",
        "lastdt = ltdl.read(10)\n",
        "ltdl.close()\n",
        "lastdt = datetime.strptime(lastdt,'%Y-%m-%d')\n",
        "diff, wr = today-lastdt.date(), ''\n",
        "\n",
        "#loop through all dates from the last date till today.\n",
        "for i in range(1,diff.days+1):\n",
        "    nextdt = lastdt+ relativedelta(days=i)\n",
        "    #check if the date is a weekend so that we can remove that from the loop , bhavcopies are not available for weekends.\n",
        "    if (nextdt.weekday() == 5 or nextdt.weekday() == 6):\n",
        "      print (nextdt.strftime('%Y-%m-%d')+\" is a weekend\")\n",
        "    else:\n",
        "      d, m, y = '%02d' % nextdt.day, '%02d' % nextdt.month, '%02d' % nextdt.year #extract day , month and year from  the the date\n",
        "      #if there is no directory already present at the path with the year as a folder then create it\n",
        "      if not os.path.isdir(base+y):\n",
        "          os.mkdir(base+y)\n",
        "          os.mkdir(base+y+'/Index')\n",
        "          os.mkdir(base+y+'/Futures')\n",
        "      zpath = base+y+'/'+d+'.zip'\n",
        "      #try to connect to the nseindia url to download the bhavcopy , 7 times , just incase website does not respond etc.\n",
        "      for i in range(7):\n",
        "          while True:\n",
        "              try:\n",
        "                  a=requests.get('https://archives.nseindia.com/content/historical/EQUITIES/'+y+'/'+dmonth[m]+'/cm'+d+dmonth[m]+y+'bhav.csv.zip')\n",
        "              except requests.ConnectionError:\n",
        "                  print('No connection, retrying')\n",
        "              break\n",
        "      #if the connection is successful\n",
        "      if a.status_code==200:\n",
        "          dload=open(zpath, 'wb')\n",
        "          dload.write(a.content)\n",
        "          dload.close()\n",
        "          #open the downlaoded bhavcopy and extract it\n",
        "          z = zipfile.ZipFile(zpath, 'r')\n",
        "          z.extractall(base+y+'/')\n",
        "          z.close()\n",
        "          os.remove(zpath)\n",
        "          #reading and storing in 2 dictionaries because we need 2 columns from the MTO file deliverable and %deliverable which is not found in the bhavcopy.\n",
        "          f, deldict = pd.read_csv(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv'), {}  #reading the raw dl-ed bhav file\n",
        "          f, deldict2 = pd.read_csv(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv'), {}  #reading the raw dl-ed bhav file\n",
        "          f = f[f['SERIES'] == 'EQ'] #retaining only EQ rows and leaving out bonds,options etc\n",
        "          deliverable = requests.get('https://archives.nseindia.com/archives/equities/mto/MTO_'+d+m+y+'.DAT').text.splitlines()\n",
        "          del deliverable[:4]\n",
        "          \n",
        "          for i in deliverable:\n",
        "              c = i.split(',')\n",
        "              if c[3] == 'EQ' :                \n",
        "                  deldict[c[2]] = c[5] #building delivarables dict\n",
        "              if c[3] == 'EQ' :                \n",
        "                  deldict2[c[2]] = c[6] #building %delivarables dict\n",
        "      \n",
        "          dfdel = pd.DataFrame(list(deldict.items()), columns = ['SYMBOL', 'DELIVERABLE'])\n",
        "          dfdel2 = pd.DataFrame(list(deldict2.items()), columns = ['SYMBOL', '%DELIVERABLE'])\n",
        "          f = f.merge(dfdel, on='SYMBOL', how='left')      #left merge of delivarables here\n",
        "          f = f.merge(dfdel2, on='SYMBOL', how='left')      #left merge of delivarables here\n",
        "\n",
        "          #sometimes nse doesnt give the index file, so the if condition\n",
        "          indices = requests.get('https://archives.nseindia.com/content/indices/ind_close_all_'+d+m+y+'.csv').content\n",
        "          if len(indices)>300:\n",
        "            indx = pd.read_csv(io.StringIO(indices.decode('utf-8'))) #reading content of indices csv and storing in DataFrame using io module\n",
        "            indx.to_csv(base+y+'/Index/Indices'+ str(nextdt.date())+'.csv', index=False)\n",
        "            indx[['Index Name', 'Index Date', 'Open Index Value', 'High Index Value', 'Low Index Value', 'Closing Index Value', 'Volume']]\n",
        "            indx = indx.rename(columns={'Index Name' : 'SYMBOL', 'Index Date' : 'BHAVCOPYDATE', 'Open Index Value' : 'OPEN', 'High Index Value' : 'HIGH', 'Low Index Value' : 'LOW', 'Closing Index Value' : 'CLOSE', 'Volume' : 'TOTTRDQTY'})\n",
        "            f=f.append(indx, ignore_index=True)\n",
        "            #write a new csv, bhavcopydate as a column in the csv and get rid of the downloaded file\n",
        "            f['BHAVCOPYDATE'] = pd.Series(str(nextdt.date().strftime('%Y-%m-%d')) for _ in range(len(f)))\n",
        "            f = f[['SYMBOL', 'BHAVCOPYDATE', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'TOTTRDQTY', 'DELIVERABLE','%DELIVERABLE']]\n",
        "            f.to_csv(base+y+'/'+str(nextdt.date())+'.csv', index=False)\n",
        "            os.remove(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv')\n",
        "            #just download and extract futures bhavcopy also\n",
        "            futures = requests.get('https://archives.nseindia.com/content/historical/DERIVATIVES/'+y+'/'+dmonth[m]+'/fo'+d+dmonth[m]+y+'bhav.csv.zip')\n",
        "            fo = open(zpath, 'wb')\n",
        "            fo.write(futures.content)\n",
        "            fo.close()\n",
        "            z, wr = zipfile.ZipFile(zpath,'r'), nextdt.date()\n",
        "            z.extractall(base+y+'/Futures')\n",
        "            z.close()\n",
        "            os.remove(zpath)\n",
        "            print(\"Downloaded bhavcopy file to \"+base+y+'/'+str(nextdt.date())+\".csv ...now inserting into DB\")\n",
        "\n",
        "            # connect to MySQL db in https://johnny.heliohost.org:2083/ UN \n",
        "            # pip install pip install mysql-connector --target=$nb_path pip install mysql-connector\n",
        "            # https://pynative.com/python-mysql-database-connection/\n",
        "\n",
        "            d, m, y = '%02d' % nextdt.day, '%02d' % nextdt.month, '%02d' % nextdt.year\n",
        "\n",
        "            #check if the path exist and connect to cloud mysql \n",
        "            #if os.path.exists(base+y):\n",
        "            try:\n",
        "              connection = mysql.connector.connect(host='johnny.heliohost.org',\n",
        "                                                  database='akini_algotrade',\n",
        "                                                  user='akini',\n",
        "                                                  password='Drink7up@home')\n",
        "              \n",
        "              db_Info = connection.get_server_info()\n",
        "              print(\"Connected to MySQL Server version \", db_Info)\n",
        "              cursor = connection.cursor()\n",
        "              cursor.execute(\"select database();\")\n",
        "              record = cursor.fetchone()\n",
        "              print(\"ingesting csv file \"+'/'+y+'-'+m+'-'+d+'.csv'+\" into DB....: \", record)\n",
        "              cursor.fast_executemany = True\n",
        "              \n",
        "              with open(base+y+'/'+y+'-'+m+'-'+d+'.csv', newline='',  encoding=\"utf8\") as csvfile:\n",
        "                csvdata = csv.reader(csvfile)\n",
        "                #skip the 1st row as it will be header\n",
        "                next(csvdata)\n",
        "                pbar = ProgressBar()\n",
        "                for row in pbar(list(csvdata)):\n",
        "                  \n",
        "                  # Prepare SQL query to INSERT a record into the database.\n",
        "                  sql = \"INSERT INTO bhavcopy (symbol, bhavcopydate, open, high, low, close, tottrdqty, deliverable, deliverable_percent) \\\n",
        "                  VALUES ('%s', '%s','%s', '%s','%s', '%s', '%s', '%s','%s');\" % (row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8])\n",
        "                  \n",
        "                  #print(sql)\n",
        "                  try:\n",
        "                    #Execute the SQL command\n",
        "                    cursor.execute(sql)\n",
        "                    #Commit your changes in the database\n",
        "                    connection.commit()\n",
        "                  except Error as e:\n",
        "                    print(\"Error while connecting to MySQL\", e)\n",
        "                    connection.rollback()\n",
        "                #pbar.next()\n",
        "                pbar.finish()\n",
        "            except Error as e:\n",
        "              print(\"Error while connecting to MySQL\", e)\n",
        "            finally:\n",
        "              if (connection.is_connected()):\n",
        "                cursor.close()\n",
        "                connection.close()\n",
        "                  \n",
        "print(\"DONE - All imports complete\")\n",
        "\n",
        "# most volatile stocks in the database in the last 1 week\n",
        "#SELECT symbol,CLOSE,`bhavcopydate`, VARIANCE(high-low) var \n",
        "#  FROM bhavcopy \n",
        "#  where `tottrdqty`> '10000000' and CLOSE between 100 and 200\n",
        "#  and `bhavcopydate` > CURRENT_DATE-5\n",
        "#  GROUP BY symbol  \n",
        "#ORDER BY `var`  DESC\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-07-04 is a weekend\n",
            "2020-07-05 is a weekend\n",
            "Downloaded bhavcopy file to /content/drive/My Drive/algotrade/2020/2020-07-06.csv ...now inserting into DB\n",
            "Connected to MySQL Server version  5.7.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 1477) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ingesting csv file /2020-07-06.csv into DB....:  ('akini_algotrade',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1477 of 1477) |####################| Elapsed Time: 0:05:27 Time:  0:05:27\n",
            "100% (1477 of 1477) |####################| Elapsed Time: 0:05:27 Time:  0:05:27"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloaded bhavcopy file to /content/drive/My Drive/algotrade/2020/2020-07-07.csv ...now inserting into DB\n",
            "Connected to MySQL Server version  5.7.30\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r                                                                               \r\rN/A% (0 of 1474) |                       | Elapsed Time: 0:00:00 ETA:  --:--:--"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ingesting csv file /2020-07-07.csv into DB....:  ('akini_algotrade',)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100% (1474 of 1474) |####################| Elapsed Time: 0:04:50 Time:  0:04:50\n",
            "100% (1474 of 1474) |####################| Elapsed Time: 0:04:50 Time:  0:04:50"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "DONE - All imports complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5_XYgsBbVhQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "ded09912-8bb4-4b07-a640-7b9c438cf6e3"
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "FileExistsError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-b5dfdb72d6c5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnb_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/notebooks'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msymlink\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/My Drive/Colab Notebooks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnb_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# or append(nb_path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileExistsError\u001b[0m: [Errno 17] File exists: '/content/drive/My Drive/Colab Notebooks' -> '/content/notebooks'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGXTBbodmqb-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "cdfb4ad3-2ca5-4ae9-f302-c227b7d1a4a7"
      },
      "source": [
        "pip install mysql.connector"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mysql.connector\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/04/e40098f3730e75bbe36a338926f566ea803550a34fb50535499f4fc4787a/mysql-connector-2.2.9.tar.gz (11.9MB)\n",
            "\u001b[K     |████████████████████████████████| 11.9MB 343kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: mysql.connector\n",
            "  Building wheel for mysql.connector (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mysql.connector: filename=mysql_connector-2.2.9-cp36-cp36m-linux_x86_64.whl size=247949 sha256=e294c5fa100b80450d8e50e3c055019d0c56434fba1fc9a23145d2fb57fae77f\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/83/a1/f8b6d4bb1bd6208bbde1608bbfa7557504bed9eaf2ecf8c175\n",
            "Successfully built mysql.connector\n",
            "Installing collected packages: mysql.connector\n",
            "Successfully installed mysql.connector\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ujWUKdMboS0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5H_h0-f8d1w7",
        "colab_type": "text"
      },
      "source": [
        "money control list of fav stocks based on news.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC9HFzXQd25p",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}