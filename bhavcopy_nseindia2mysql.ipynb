{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bhavcopy_nseindia2mysql.ipynb",
      "provenance": [],
      "mount_file_id": "1wpeVd-eds_hCQW83PZg9epPy9KzIGStl",
      "authorship_tag": "ABX9TyNZBAhkA6LSlfZlrloAXJOf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyakini/algo_intraday/blob/master/bhavcopy_nseindia2mysql.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lWvceVmjXzEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, os, io, pandas as pd\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "import csv\n",
        "\n",
        "base = '/content/drive/My Drive/algotrade/'\n",
        "today = datetime.today().date()\n",
        "dmonth={'01':'JAN','02':'FEB','03':'MAR','04':'APR','05':'MAY','06':'JUN','07':'JUL','08':'AUG','09':'SEP','10':'OCT','11':'NOV','12':'DEC'}\n",
        "\n",
        "# Before running this script , create a file called bhavcopy_date.txt and write the date from which you want to download EOD data\n",
        "# Opening file named bhavcopy_date.txt , which keeps track of the last downloaded date.\n",
        "ltdl = open(base+'bhavcopy_date.txt','r')\n",
        "lastdt = ltdl.read(10)\n",
        "ltdl.close()\n",
        "lastdt = datetime.strptime(lastdt,'%Y-%m-%d')\n",
        "diff, wr = today-lastdt.date(), ''\n",
        "\n",
        "for i in range(1,diff.days+1):\n",
        "    nextdt = lastdt+ relativedelta(days=i)\n",
        "    if (nextdt.weekday() == 5 or nextdt.weekday() == 6):\n",
        "      print (\"its a saturday or a sunday\")\n",
        "    else:\n",
        "      print (nextdt.weekday())\n",
        "      print (nextdt)\n",
        "      print (\"created folders\")\n",
        "\n",
        "      for i in range(7):\n",
        "          while True:\n",
        "              try:\n",
        "                  print (\"getting bhavcopy csv\")\n",
        "              except requests.ConnectionError:\n",
        "                  print('No connection, retrying')\n",
        "              break\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCQ7pBunZZyl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, os, io, pandas as pd\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "import mysql.connector\n",
        "from mysql.connector import Error\n",
        "import csv\n",
        "\n",
        "#set the path to where the bhavcopies will be downloaded\n",
        "base = '/content/drive/My Drive/algotrade/'\n",
        "today = datetime.today().date()\n",
        "dmonth={'01':'JAN','02':'FEB','03':'MAR','04':'APR','05':'MAY','06':'JUN','07':'JUL','08':'AUG','09':'SEP','10':'OCT','11':'NOV','12':'DEC'}\n",
        "\n",
        "# Before running this script , file called bhavcopy_date.txt need to be present in the \"base\" path.\n",
        "# Opening file named bhavcopy_date.txt , it keeps track of the last downloaded date.\n",
        "ltdl = open(base+'bhavcopy_date.txt','r')\n",
        "lastdt = ltdl.read(10)\n",
        "ltdl.close()\n",
        "lastdt = datetime.strptime(lastdt,'%Y-%m-%d')\n",
        "diff, wr = today-lastdt.date(), ''\n",
        "\n",
        "#loop through all dates from the last date till today.\n",
        "for i in range(1,diff.days+1):\n",
        "    nextdt = lastdt+ relativedelta(days=i)\n",
        "    #check if the date is a weekend so that we can remove that from the loop , bhavcopies are not available for weekends.\n",
        "    if (nextdt.weekday() == 5 or nextdt.weekday() == 6):\n",
        "      print (nextdt.strftime('%Y-%m-%d')+\" is a weekend\")\n",
        "    else:\n",
        "      d, m, y = '%02d' % nextdt.day, '%02d' % nextdt.month, '%02d' % nextdt.year #extract day , month and year from  the the date\n",
        "      #if there is no directory already present at the path with the year as a folder then create it\n",
        "      if not os.path.isdir(base+y):\n",
        "          os.mkdir(base+y)\n",
        "          os.mkdir(base+y+'/Index')\n",
        "          os.mkdir(base+y+'/Futures')\n",
        "      zpath = base+y+'/'+d+'.zip'\n",
        "      #try to connect to the nseindia url to download the bhavcopy , 7 times , just incase website does not respond etc.\n",
        "      for i in range(7):\n",
        "          while True:\n",
        "              try:\n",
        "                  a=requests.get('https://archives.nseindia.com/content/historical/EQUITIES/'+y+'/'+dmonth[m]+'/cm'+d+dmonth[m]+y+'bhav.csv.zip')\n",
        "              except requests.ConnectionError:\n",
        "                  print('No connection, retrying')\n",
        "              break\n",
        "      #if the connection is successful\n",
        "      if a.status_code==200:\n",
        "          dload=open(zpath, 'wb')\n",
        "          dload.write(a.content)\n",
        "          dload.close()\n",
        "          #open the downlaoded bhavcopy and extract it\n",
        "          z = zipfile.ZipFile(zpath, 'r')\n",
        "          z.extractall(base+y+'/')\n",
        "          z.close()\n",
        "          os.remove(zpath)\n",
        "          #reading and storing in 2 dictionaries because we need 2 columns from the MTO file deliverable and %deliverable which is not found in the bhavcopy.\n",
        "          f, deldict = pd.read_csv(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv'), {}  #reading the raw dl-ed bhav file\n",
        "          f, deldict2 = pd.read_csv(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv'), {}  #reading the raw dl-ed bhav file\n",
        "          f = f[f['SERIES'] == 'EQ'] #retaining only EQ rows and leaving out bonds,options etc\n",
        "          deliverable = requests.get('https://archives.nseindia.com/archives/equities/mto/MTO_'+d+m+y+'.DAT').text.splitlines()\n",
        "          del deliverable[:4]\n",
        "          \n",
        "          for i in deliverable:\n",
        "              c = i.split(',')\n",
        "              if c[3] == 'EQ' :                \n",
        "                  deldict[c[2]] = c[5] #building delivarables dict\n",
        "              if c[3] == 'EQ' :                \n",
        "                  deldict2[c[2]] = c[6] #building %delivarables dict\n",
        "      \n",
        "          dfdel = pd.DataFrame(list(deldict.items()), columns = ['SYMBOL', 'DELIVERABLE'])\n",
        "          dfdel2 = pd.DataFrame(list(deldict2.items()), columns = ['SYMBOL', '%DELIVERABLE'])\n",
        "          f = f.merge(dfdel, on='SYMBOL', how='left')      #left merge of delivarables here\n",
        "          f = f.merge(dfdel2, on='SYMBOL', how='left')      #left merge of delivarables here\n",
        "\n",
        "          #sometimes nse doesnt give the index file, so the if condition\n",
        "          indices = requests.get('https://archives.nseindia.com/content/indices/ind_close_all_'+d+m+y+'.csv').content\n",
        "          if len(indices)>300:\n",
        "            indx = pd.read_csv(io.StringIO(indices.decode('utf-8'))) #reading content of indices csv and storing in DataFrame using io module\n",
        "            indx.to_csv(base+y+'/Index/Indices'+ str(nextdt.date())+'.csv', index=False)\n",
        "            indx[['Index Name', 'Index Date', 'Open Index Value', 'High Index Value', 'Low Index Value', 'Closing Index Value', 'Volume']]\n",
        "            indx = indx.rename(columns={'Index Name' : 'SYMBOL', 'Index Date' : 'BHAVCOPYDATE', 'Open Index Value' : 'OPEN', 'High Index Value' : 'HIGH', 'Low Index Value' : 'LOW', 'Closing Index Value' : 'CLOSE', 'Volume' : 'TOTTRDQTY'})\n",
        "            f=f.append(indx, ignore_index=True)\n",
        "            #write a new csv, bhavcopydate as a column in the csv and get rid of the downloaded file\n",
        "            f['BHAVCOPYDATE'] = pd.Series(str(nextdt.date().strftime('%Y-%m-%d')) for _ in range(len(f)))\n",
        "            f = f[['SYMBOL', 'BHAVCOPYDATE', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'TOTTRDQTY', 'DELIVERABLE','%DELIVERABLE']]\n",
        "            f.to_csv(base+y+'/'+str(nextdt.date())+'.csv', index=False)\n",
        "            os.remove(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv')\n",
        "            #just download and extract futures bhavcopy also\n",
        "            futures = requests.get('https://archives.nseindia.com/content/historical/DERIVATIVES/'+y+'/'+dmonth[m]+'/fo'+d+dmonth[m]+y+'bhav.csv.zip')\n",
        "            fo = open(zpath, 'wb')\n",
        "            fo.write(futures.content)\n",
        "            fo.close()\n",
        "            z, wr = zipfile.ZipFile(zpath,'r'), nextdt.date()\n",
        "            z.extractall(base+y+'/Futures')\n",
        "            z.close()\n",
        "            os.remove(zpath)\n",
        "            print(\"Downloaded bhavcopy file to \"+base+y+'/'+str(nextdt.date())+\".csv ...now inserting into DB\")\n",
        "\n",
        "            # connect to MySQL db in https://johnny.heliohost.org:2083/ UN \n",
        "            # pip install pip install mysql-connector --target=$nb_path pip install mysql-connector\n",
        "            # https://pynative.com/python-mysql-database-connection/\n",
        "\n",
        "            d, m, y = '%02d' % nextdt.day, '%02d' % nextdt.month, '%02d' % nextdt.year\n",
        "\n",
        "            #check if the path exist and connect to cloud mysql \n",
        "            if os.path.exists(base+y):\n",
        "              try:\n",
        "                connection = mysql.connector.connect(host='johnny.heliohost.org',\n",
        "                                                    database='akini_algotrade',\n",
        "                                                    user='akini',\n",
        "                                                    password='Drink7up@home')\n",
        "                if connection.is_connected():\n",
        "                    db_Info = connection.get_server_info()\n",
        "                    print(\"Connected to MySQL Server version \", db_Info)\n",
        "                    cursor = connection.cursor()\n",
        "                    cursor.execute(\"select database();\")\n",
        "                    record = cursor.fetchone()\n",
        "                    print(\"You're connected to database: \", record)\n",
        "                  \n",
        "                    with open(base+y+'/'+y+'-'+m+'-'+d+'.csv', newline='',  encoding=\"utf8\") as csvfile:\n",
        "                      csvdata = csv.reader(csvfile)\n",
        "                      #skip the 1st row as it will be header\n",
        "                      next(csvdata)\n",
        "\n",
        "                      for row in csvdata:\n",
        "                        # Prepare SQL query to INSERT a record into the database.\n",
        "                        sql = \"INSERT INTO bhavcopy (symbol, bhavcopydate, open, high, low, close, tottrdqty, deliverable, deliverable_percent) \\\n",
        "                        VALUES ('%s', '%s','%s', '%s','%s', '%s', '%s', '%s','%s');\" % (row[0], row[1], row[2], row[3], row[4], row[5], row[6], row[7], row[8])\n",
        "                        print(sql)\n",
        "\n",
        "                        try:\n",
        "                          # Execute the SQL command\n",
        "                          cursor.execute(sql)\n",
        "                          # Commit your changes in the database\n",
        "                          connection.commit()\n",
        "                        except Error as e:\n",
        "                          print(\"Error while connecting to MySQL\", e)\n",
        "                          connection.rollback()\n",
        "\n",
        "              except Error as e:\n",
        "                print(\"Error while connecting to MySQL\", e)\n",
        "              finally:\n",
        "                if (connection.is_connected()):\n",
        "                  cursor.close()\n",
        "                  connection.close()\n",
        "                  \n",
        "print(\"DONE - All imports complete\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5_XYgsBbVhQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os, sys\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "nb_path = '/content/notebooks'\n",
        "os.symlink('/content/drive/My Drive/Colab Notebooks', nb_path)\n",
        "sys.path.insert(0, nb_path)  # or append(nb_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ujWUKdMboS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "191090f1-03a8-48a3-eb26-277cc774adfe"
      },
      "source": [
        "pip install pip install mysql-connector --target=$nb_path pip install mysql-connector"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.6/dist-packages (19.3.1)\n",
            "Collecting install\n",
            "  Using cached https://files.pythonhosted.org/packages/41/cf/e3e6b4d494051c07261cae8c403f0f0d0cedad43d980e5255f2c88fd5edf/install-1.3.3-py3-none-any.whl\n",
            "Processing /root/.cache/pip/wheels/8c/83/a1/f8b6d4bb1bd6208bbde1608bbfa7557504bed9eaf2ecf8c175/mysql_connector-2.2.9-cp36-cp36m-linux_x86_64.whl\n",
            "Installing collected packages: install, mysql-connector\n",
            "Successfully installed install-1.3.3 mysql-connector-2.2.9\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}