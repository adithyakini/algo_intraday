{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "get_bhavcopy.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMqBUgJ5HH6Xko72/2gongt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adithyakini/algo_intraday/blob/master/get_bhavcopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvHKaIetjTEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests, zipfile, os, io, pandas as pd\n",
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "base = '/content/'\n",
        "t = datetime.today().date()\n",
        "dmonth={'01':'JAN','02':'FEB','03':'MAR','04':'APR','05':'MAY','06':'JUN','07':'JUL','08':'AUG','09':'SEP','10':'OCT','11':'NOV','12':'DEC'}\n",
        "\n",
        "# Before running this script , create a file called log.txt and write the date from which you want to download EOD data\n",
        "# Opening file named log.txt , which keeps track of the last downloaded date.\n",
        "ltdl = open(base+'log.txt','r')\n",
        "lastdt = ltdl.read(10)\n",
        "ltdl.close()\n",
        "lastdt = datetime.strptime(lastdt,'%Y-%m-%d')\n",
        "diff, wr = t-lastdt.date(), ''\n",
        "\n",
        "for i in range(1,diff.days+1):\n",
        "    nextdt = lastdt+ relativedelta(days=i)\n",
        "    d, m, y = '%02d' % nextdt.day, '%02d' % nextdt.month, '%02d' % nextdt.year\n",
        "    if not os.path.isdir(base+y):\n",
        "        os.mkdir(base+y)\n",
        "        os.mkdir(base+y+'/Index')\n",
        "        os.mkdir(base+y+'/Futures')\n",
        "    zpath = base+y+'/'+d+'.zip'\n",
        "    \n",
        "    for i in range(7):\n",
        "        while True:\n",
        "            try:\n",
        "                a=requests.get('https://archives.nseindia.com/content/historical/EQUITIES/'+y+'/'+dmonth[m]+'/cm'+d+dmonth[m]+y+'bhav.csv.zip')\n",
        "            except requests.ConnectionError:\n",
        "                print('No connection, retrying')\n",
        "            break\n",
        "            \n",
        "    if a.status_code==200:\n",
        "        dload=open(zpath, 'wb')\n",
        "        dload.write(a.content)\n",
        "        dload.close()\n",
        "        z = zipfile.ZipFile(zpath, 'r')\n",
        "        z.extractall(base+y+'/')\n",
        "        z.close()\n",
        "        os.remove(zpath)\n",
        "        f, deldict = pd.read_csv(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv'), {}  #reading the raw dl-ed bhav file\n",
        "        f = f[f['SERIES'] == 'EQ'] #retaining only EQ rows and leaving out bonds,options etc\n",
        "        deliverable = requests.get('https://archives.nseindia.com/archives/equities/mto/MTO_'+d+m+y+'.DAT').text.splitlines()\n",
        "        del deliverable[:4]\n",
        "\n",
        "        for i in deliverable:\n",
        "            c = i.split(',')\n",
        "            if c[3] == 'EQ' :                \n",
        "                deldict[c[2]] = c[5] #building delivarables dict\n",
        "     \n",
        "        dfdel = pd.DataFrame(list(deldict.items()), columns = ['SYMBOL', 'DELIVERABLE'])\n",
        "        f = f.merge(dfdel, on='SYMBOL', how='left')      #left merge of delivarables here\n",
        "        \n",
        "        indices = requests.get('https://archives.nseindia.com/content/indices/ind_close_all_'+d+m+y+'.csv').content\n",
        "  \n",
        "#sometimes nse doesnt give the index file, so the if condition\n",
        "        if len(indices)>300:\n",
        "          indx = pd.read_csv(io.StringIO(indices.decode('utf-8'))) #reading content of indices csv and storing in DataFrame using io module\n",
        "          indx.to_csv(base+y+'/Index/Indices'+ str(nextdt.date())+'.csv', index=False)\n",
        "          indx[['Index Name', 'Index Date', 'Open Index Value', 'High Index Value', 'Low Index Value', 'Closing Index Value', 'Volume']]\n",
        "          indx = indx.rename(columns={'Index Name' : 'SYMBOL', 'Index Date' : 'TIMESTAMP', 'Open Index Value' : 'OPEN', 'High Index Value' : 'HIGH', 'Low Index Value' : 'LOW', 'Closing Index Value' : 'CLOSE', 'Volume' : 'TOTTRDQTY'})\n",
        "          f=f.append(indx, ignore_index=True)\n",
        "          f['TIMESTAMP'] = pd.Series(str(nextdt.date().strftime('%Y%m%d')) for _ in range(len(f)))\n",
        "          f = f[['SYMBOL', 'TIMESTAMP', 'OPEN', 'HIGH', 'LOW', 'CLOSE', 'TOTTRDQTY', 'DELIVERABLE']]\n",
        "          f.to_csv(base+y+'/'+str(nextdt.date())+'.csv', index=False)\n",
        "          os.remove(base+y+'/cm'+d+dmonth[m]+y+'bhav.csv')\n",
        "          futures = requests.get('https://archives.nseindia.com/content/historical/DERIVATIVES/'+y+'/'+dmonth[m]+'/fo'+d+dmonth[m]+y+'bhav.csv.zip')\n",
        "          fo = open(zpath, 'wb')\n",
        "          fo.write(futures.content)\n",
        "          fo.close()\n",
        "          z, wr = zipfile.ZipFile(zpath,'r'), nextdt.date()\n",
        "          z.extractall(base+y+'/Futures')\n",
        "          z.close()\n",
        "          os.remove(zpath)"
      ],
      "execution_count": 1,
      "outputs": []
    }
  ]
}